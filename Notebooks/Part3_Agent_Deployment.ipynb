{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb\n",
        "!pip install openai\n",
        "!pip install tqdm\n",
        "!pip install sounddevice\n",
        "!pip install whisper\n",
        "!pip install gtts\n",
        "!pip install beautifulsoup4\n",
        "!pip install tavily-python\n",
        "!pip install lxml\n",
        "!pip install pyttsx3\n",
        "!pip install langchain_openai\n",
        "!pip install langchain-community\n",
        "!pip install langchain-google-genai\n",
        "!pip install langsmith\n",
        "!pip install PyPDF2\n",
        "\n",
        "# Common dependencies for some of the above packages\n",
        "# BeautifulSoup often works best with an external parser like lxml\n",
        "# Tavily and OpenAI clients use an HTTP client like httpx\n",
        "!pip install lxml\n",
        "!pip install httpx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nZBqgN5unCwA",
        "outputId": "f2429f64-3ae6-4262-ebbe-a56090bfeef2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-1.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.11.7)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.36.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.36.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.74.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.17.4)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.4)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.58b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.34.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-1.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=84739fbe6715f31d56403268de43d66ef313c5b6b6184c9c8ce8132fb8a378ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, pybase64, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.36.0\n",
            "    Uninstalling opentelemetry-api-1.36.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.36.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.57b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.57b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.57b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.36.0\n",
            "    Uninstalling opentelemetry-sdk-1.36.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.36.0\n",
            "Successfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.1.0 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 mmh3-5.2.0 onnxruntime-1.22.1 opentelemetry-api-1.37.0 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 opentelemetry-proto-1.37.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 uvloop-0.21.0 watchfiles-1.1.0\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.107.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Collecting sounddevice\n",
            "  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice) (2.23)\n",
            "Downloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: sounddevice\n",
            "Successfully installed sounddevice-0.5.2\n",
            "Collecting whisper\n",
            "  Downloading whisper-1.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from whisper) (1.17.0)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41120 sha256=dc55162edd6eeda593bafca1ae1c3232e18a4627d6bb52db1b385917901e2dbf\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/b8/4e/9c4c3351d670e06746a340fb4b7d854c76517eec225e5b32b1\n",
            "Successfully built whisper\n",
            "Installing collected packages: whisper\n",
            "Successfully installed whisper-1.1.10\n",
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from gtts) (2.32.4)\n",
            "Collecting click<8.2,>=7.1 (from gtts)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gtts) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gtts) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gtts) (2025.8.3)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: click, gtts\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.2.1\n",
            "    Uninstalling click-8.2.1:\n",
            "      Successfully uninstalled click-8.2.1\n",
            "Successfully installed click-8.1.8 gtts-2.5.4\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Collecting tavily-python\n",
            "  Downloading tavily_python-0.7.12-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from tavily-python) (2.32.4)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tavily-python) (0.11.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from tavily-python) (0.28.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (2025.8.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->tavily-python) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->tavily-python) (4.15.0)\n",
            "Downloading tavily_python-0.7.12-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: tavily-python\n",
            "Successfully installed tavily-python-0.7.12\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (5.4.0)\n",
            "Collecting pyttsx3\n",
            "  Downloading pyttsx3-2.99-py3-none-any.whl.metadata (6.2 kB)\n",
            "Downloading pyttsx3-2.99-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pyttsx3\n",
            "Successfully installed pyttsx3-2.99\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.76 (from langchain_openai)\n",
            "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.107.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.4.27)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (25.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (2.11.7)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.104.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.76->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.5.0)\n",
            "Downloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-core, langchain_openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.75\n",
            "    Uninstalling langchain-core-0.3.75:\n",
            "      Successfully uninstalled langchain-core-0.3.75\n",
            "Successfully installed langchain-core-0.3.76 langchain_openai-0.3.33\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.76)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.43)\n",
            "Collecting requests<3,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.27)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (0.24.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-community-0.3.29 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langchain-core>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.3.76)\n",
            "Collecting google-ai-generativelanguage<1,>=0.7 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.11.7)\n",
            "Collecting filetype<2,>=1.2 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (0.4.27)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.32.5)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.75->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.24.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.12-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.7.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain-google-genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.7.0 langchain-google-genai-2.1.12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "0237a60910634561853e493db92e314f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.12/dist-packages (0.4.27)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith) (3.11.3)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langsmith) (25.0)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langsmith) (2.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.24.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langsmith) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langsmith) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langsmith) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (5.4.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c81287a",
        "outputId": "51caeef7-ec2e-40bb-80e7-5a71a69260ab"
      },
      "source": [
        "!pip install google-search-results"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from google-search-results) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2025.8.3)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32010 sha256=41f0599e2e2ab1646d500e5bce0659477b3f7c7b869612b253f09d6dce5f9508\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/47/f5/89b7e770ab2996baf8c910e7353d6391e373075a0ac213519e\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y5YSKSqMJA-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da25af08-8c28-4832-d89a-c3f8c5558613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# STEP - 1 : Imports\n",
        "# ============================================\n",
        "\n",
        "# Standard Library Imports\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "\n",
        "# Third-Party Library Imports\n",
        "import chromadb\n",
        "import openai\n",
        "import tqdm\n",
        "import pyttsx3\n",
        "import gtts\n",
        "from google.colab import drive\n",
        "from bs4 import BeautifulSoup\n",
        "from tavily import TavilyClient\n",
        "\n",
        "# LangChain and related framework imports\n",
        "import langchain\n",
        "from langchain import hub\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser # Corrected import path\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import OllamaEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# STEP - 2 : Load API keys (Colab + Env)\n",
        "# =========================================\n",
        "import os\n",
        "\n",
        "# Attempt to fetch from Colab userdata if available\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    _colab_available = True\n",
        "except ImportError:\n",
        "    _colab_available = False\n",
        "\n",
        "def get_key(key_name: str) -> str:\n",
        "    \"\"\"Fetch API key from Colab userdata first, then environment variables.\"\"\"\n",
        "    key = None\n",
        "    if _colab_available:\n",
        "        key = userdata.get(key_name)\n",
        "    if not key:\n",
        "        key = os.environ.get(key_name)\n",
        "    if not key:\n",
        "        print(f\"❌ {key_name} not found! Please add it to Colab secrets or environment variables.\")\n",
        "    else:\n",
        "        print(f\"✅ {key_name} loaded successfully!\")\n",
        "    return key\n",
        "\n",
        "# Fetch all keys\n",
        "OPENAI_API_KEY = get_key(\"OPENAI_API_KEY\")\n",
        "TAVILY_API_KEY = get_key(\"TAVILY_API_KEY\")\n",
        "SERPAPI_API_KEY = get_key(\"SERPAPI_API_KEY\")\n",
        "LANGCHAIN_API_KEY = get_key(\"LANGCHAIN_API_KEY\")\n",
        "# LANGSMITH_API_KEY = get_key(\"LANGSMITH_API_KEY\")\n",
        "# HF_TOKEN = get_key(\"HF_TOKEN\")\n",
        "# Optional: Pinecone if you use it\n",
        "# PINECONE_API_KEY = get_key(\"PINECONE_API_KEY\")\n",
        "\n",
        "# Set OpenAI key for SDKs\n",
        "if OPENAI_API_KEY:\n",
        "    import openai\n",
        "    openai.api_key = OPENAI_API_KEY\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gZdqyv_wMWc",
        "outputId": "b1e17aa2-b3b8-417f-d0e2-bb5504aa1ad5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ OPENAI_API_KEY loaded successfully!\n",
            "✅ TAVILY_API_KEY loaded successfully!\n",
            "✅ SERPAPI_API_KEY loaded successfully!\n",
            "✅ LANGCHAIN_API_KEY loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# ---------- MOUNT THE GOOGLE DRIVE -------------\n",
        "# ================================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(f\"✅ Google Drive mounted successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdkadBgywvdD",
        "outputId": "c8737a8f-d39b-43d4-a57b-46dbc3b80a89"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✅ Google Drive mounted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# STEP - 3 : Importing all embedded chunks\n",
        "# ============================================\n",
        "\n",
        "all_embedded_file_path = \"/content/drive/MyDrive/Ironhack_final_project/all_embedded_chunks.json\"\n",
        "\n",
        "with open(all_embedded_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    all_embedded_chunks = json.load(f)\n",
        "\n",
        "print(f\"✅ Loaded {len(all_embedded_chunks)} chunks\")\n",
        "print(all_embedded_chunks[0])  # preview first chunk"
      ],
      "metadata": {
        "id": "1CbpzVP9Jl2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbeee7d2-bceb-4b6d-c44a-cf09c170aee0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 164 chunks\n",
            "{'video_id': 'tQ84XYcP-nA', 'chunk_index': 0, 'text': \"Every week there's a new AI tool making headlines, and right now there are more AI video generators than ever. But most of them don't work as well as you'd expect. Some generate great videos, but only if you stay within their style limits. If you try to get more creative, like detailed anime or wild fantasy worlds, they often mess up, and most of the time they're too expensive or just confusing to use. I've tested every major tool that's come out recently, and I've seen where they shine and where they completely fall apart. So, in this video, I'm going to show you the AI video tools that actually deliver the kind of quality you'd want to publish. The best way to use them without wasting hours learning clunky software, and the one platform that ties everything together, so you can create full videos without switching between five different sites. Let's break it down. All right, let's start with Seedance 1.0. Seance is by danceance's flagship AI video generator, the same company behind Tik Tok. And it's currently ranked number one on the leading video AI benchmark. And unlike most tools that glitch out when you get specific, Cance was built for precision and it actually follows your complex prompts. If you've tried video generators before and felt limited, this one changes the game. To use it, I'm heading into the text to video tab and selecting seed dance in the drop- down menu. By the way, if you want to know how I ax all of the AI models in just one tool, it's because I use open art. I'll leave a link to it down below so that you can follow along. Seedance supports both image and text generation. But for now, we're starting fresh with a prompt. Now, I'll type in my prompt. For example, a lone cyberpunk courier speeds through a neon lit city on a futuristic motorcycle. Rain falls in slow motion, bouncing off chrome surfaces and glowing street sign. The camera tracks from behind as the bike swerves between flying cars and under flickering holograms. Midway, the courier skids around a corner and removes their helmet, revealing a determined expression. In the distance, a tower explodes in a pulse of electric blue light. Moody, high contrast lighting, reflective puddles, 24 fps, cinematic motion blur. As you can see, I try to be as in-depth as I possibly can. This is very important for all models we are going to cover today. The more specific you are in your prompt, the better the result will come out. But I get that for a beginner, this can be challenging. So, I've come up with a simple solution to help you out. To create a very in-depth prompt, I head to chat GPT and paste in this prompt. Create a super in-depth prompt for an AI generated video using Seance Model. The prompt idea is a lone courier speeding through a neon lit city on\", 'embedding': [0.019356219097971916, 0.017160408198833466, -0.040577374398708344, -0.016167782247066498, 0.0028857612051069736, -0.057211387902498245, 0.0223641786724329, 0.02416895516216755, 0.044938914477825165, 0.05561717227101326, 0.036606866866350174, -0.06274603307247162, -0.02989911660552025, -0.0685814768075943, -0.004587138071656227, -0.020800039172172546, -0.05206777900457382, -0.03946442902088165, 0.006655110511928797, -0.0006570511613972485, -0.0026338445022702217, 0.011054251343011856, -0.03029015101492405, 0.04478851705789566, 0.04045705497264862, -0.04223174974322319, 0.006621270906180143, 0.06918306648731232, 0.01625801995396614, 0.00567376334220171, -0.0016148982103914022, -0.024695347994565964, -0.004222423303872347, -0.053992871195077896, -0.006839348003268242, 0.008971239440143108, 0.0020322524942457676, 0.0011890840250998735, -0.00865540374070406, 0.004162264056503773, 0.0003628350968938321, 0.00685438746586442, 0.0577528215944767, -0.006549831945449114, 0.001814175513572991, 0.022574735805392265, 0.013799013569951057, -0.01735592633485794, -0.01916070096194744, 0.022619854658842087, -0.0765826478600502, 0.09059973806142807, -0.021115874871611595, 0.04617217928171158, 0.0008036891813389957, -0.01917574182152748, -0.04214151203632355, 0.007211582735180855, -0.019265979528427124, -0.004647297319024801, 0.05023292452096939, -0.0011778040789067745, -0.0009860467398539186, 0.034140340983867645, 0.008610283955931664, -0.010430099442601204, -0.01949157752096653, 0.010430099442601204, 0.010212022811174393, -0.015017237514257431, 0.02601884864270687, 0.0022484497167170048, 0.00993378646671772, -0.004587138071656227, -0.07718423753976822, -0.015716588124632835, 0.003011719323694706, 0.02564285509288311, -0.005963279400020838, -0.031162459403276443, 0.02418399415910244, -0.0032767958473414183, -0.028981689363718033, -0.011129450052976608, -0.05513589829206467, -0.018634308129549026, -0.03218516707420349, -0.03744909539818764, -0.05549685284495354, -0.015348113141953945, -0.011264808475971222, 0.03781004995107651, -0.004760095849633217, 0.046713609248399734, 0.05014268308877945, 0.05525621399283409, -0.006944626569747925, 0.0013197421794757247, 0.056339081376791, 0.03465169295668602, 0.05600820481777191, -0.010933932848274708, -0.01630314067006111, 0.014212608337402344, 0.03549392148852348, 0.008918600156903267, -0.011648323386907578, -0.03260628134012222, -0.038110844790935516, 0.022529616951942444, -0.09553278982639313, -0.01693481206893921, -0.038471803069114685, 0.03140309825539589, 0.017476243898272514, -0.02057444304227829, 0.026530202478170395, 0.03507280722260475, 0.014693882316350937, 0.010046584531664848, -0.044968992471694946, 0.0375092551112175, 0.0030060794670134783, 0.02594364993274212, 0.017927438020706177, -0.04187079519033432, -0.00383326830342412, -0.03787020966410637, -0.0017897358629852533, -0.02200322411954403, 0.011994238011538982, 0.020033009350299835, 0.01989765092730522, -0.007256702054291964, -0.020108209922909737, -0.02640988491475582, -0.005959519650787115, 0.009978905320167542, 0.009256995283067226, 0.029177207499742508, -0.02522174082696438, -0.031282778829336166, 0.0042036231607198715, 0.006452072877436876, -0.053601838648319244, -0.04120904579758644, -0.027928903698921204, -0.011798720806837082, -0.024394551292061806, 0.02529693953692913, -0.018950143828988075, -0.025131501257419586, -0.04578114300966263, -0.0024195273872464895, 0.0012360833352431655, 0.008775721304118633, -0.044999074190855026, 0.030214952304959297, -0.03759949281811714, -0.015039796940982342, -0.0003167757240589708, -0.022123541682958603, -0.02455998957157135, -0.012159676291048527, -0.0605803020298481, -0.004248742945492268, -0.029342643916606903, 0.012783827260136604, -0.05522613599896431, 0.02961336076259613, -0.00076796964276582, -0.02594364993274212, -0.0022258900571614504, -0.0367271862924099, 0.04322437569499016, -0.03335827216506004, 0.001816055504605174, -0.0324859619140625, -0.010933932848274708, -0.015205235220491886, -0.013926852494478226, 0.05026300251483917, -0.0076514966785907745, 0.005884320475161076, 0.006617510691285133, -0.0040419455617666245, 0.012016798369586468, -0.0066964696161448956, -0.0024590068496763706, -0.011340007185935974, -0.0332680307328701, 0.018513990566134453, 0.031132379546761513, 0.017521364614367485, 0.04433732107281685, -0.0324859619140625, 0.07652249187231064, -0.021567068994045258, 0.07772567123174667, -0.03967498615384102, 0.07170975208282471, 0.033809464424848557, -0.015761706978082657, -0.023928318172693253, 0.02422911301255226, 0.01550603099167347, -0.00014205557818058878, -0.013806533999741077, -0.030741345137357712, 0.013468138873577118, 0.05167674273252487, -0.00833956804126501, 0.002842521760612726, -0.02016836777329445, -0.052849847823381424, -0.02125123329460621, -0.014144929125905037, 0.033689144998788834, -0.03110230155289173, 0.040908247232437134, -0.03176405280828476, -0.020393965765833855, 0.014295327477157116, -0.02520669996738434, 0.011362566612660885, -0.012498071417212486, 0.020348845049738884, -0.047796476632356644, 0.00847492553293705, 0.011159529909491539, 0.02021348848938942, 0.02567293308675289, -0.008023731410503387, -0.040306657552719116, 0.036997903138399124, -0.02822970040142536, 0.016363300383090973, -0.014716441743075848, 0.02666556090116501, 0.005083451513200998, 0.02636476419866085, -0.012513111345469952, 0.046803850680589676, 0.003970506601035595, 0.01737096533179283, 0.010783534497022629, -0.034862250089645386, -0.01499467808753252, -0.01352077815681696, 0.037388935685157776, 0.07904917746782303, -0.008076370693743229, 0.015430832281708717, -0.00029938595253042877, 0.00958787091076374, -0.0641898512840271, 0.00550832599401474, 0.014656282030045986, -0.026785878464579582, 0.0023819277994334698, 0.020709801465272903, 0.006467112805694342, -0.03862220048904419, 0.006527272053062916, 0.005899360403418541, 0.02055940218269825, -0.04827775061130524, -0.020679721608757973, 0.014859319664537907, 0.001661897636950016, 0.008083891123533249, 0.0237779188901186, 0.04322437569499016, -0.0015086797066032887, -0.029026808217167854, -0.028274819254875183, 0.03540368378162384, 0.0015866985777392983, 0.007474779151380062, 0.04364548996090889, -0.029523121193051338, -0.020078130066394806, -0.0026206846814602613, 0.02055940218269825, -0.010264662094414234, 0.0034159140195697546, -0.012227355502545834, -0.02344704419374466, 0.012941746041178703, -0.06912291049957275, 0.024981103837490082, -0.044547878205776215, -0.04806719347834587, -0.03290707617998123, 0.0072416625916957855, -0.01914566196501255, -0.0009254175238311291, 0.05820401385426521, -0.021100835874676704, 0.035884957760572433, 0.008602764457464218, -0.10082679986953735, 0.014347966760396957, 0.010708335787057877, 0.01080609392374754, 0.03711821883916855, -0.05017276480793953, 0.013588456436991692, -0.009941305965185165, -0.01191903930157423, 0.027943942695856094, 0.08229777216911316, -0.0009169576223939657, -0.018649348989129066, -0.01729576662182808, -0.016047462821006775, 0.06003887206315994, -0.02779354527592659, 0.029071928933262825, -0.07080736756324768, -0.026244446635246277, -0.014859319664537907, -0.007501098792999983, -0.00938483327627182, -0.05733170732855797, -0.027206992730498314, 0.01550603099167347, 0.00995634589344263, 0.01550603099167347, -0.028741052374243736, 0.011791201308369637, 0.004839054774492979, -0.010888813063502312, 0.012866546399891376, -0.0006885407492518425, -0.05889584496617317, -0.026470042765140533, -0.019296059384942055, 0.041720397770404816, 0.009851067326962948, -0.06196396425366402, -0.0237779188901186, 0.010715855285525322, 0.03254612162709236, -0.023928318172693253, 0.012513111345469952, -0.010234582237899303, -0.034140340983867645, 0.029132086783647537, 0.005151130724698305, -0.041359443217515945, -0.01009922381490469, -0.00012748577864840627, -0.03639630973339081, 0.03633615002036095, 0.022529616951942444, -0.04659329354763031, 0.008835881017148495, -0.0411188043653965, -0.039945702999830246, -0.016694175079464912, 0.019311100244522095, 0.018905024975538254, 0.014355486258864403, -0.005497045814990997, -0.004756336100399494, -0.03456145524978638, 0.027252113446593285, 0.004722496494650841, 0.0014898799126967788, -0.009490111842751503, 0.005805361550301313, 0.00722286244854331, 0.0006523511838167906, -0.015460911206901073, -0.010196982882916927, -0.009497632272541523, 0.017446164041757584, -0.013971971347928047, 0.04018633812665939, -0.00044719898141920567, -0.03224532678723335, -0.012099516578018665, -0.027507789433002472, 0.003891547443345189, 0.03600527346134186, 0.02665052004158497, -0.00307187857106328, -0.06346794217824936, 0.0169498510658741, 0.022890571504831314, -0.10437619686126709, -0.03832140192389488, 0.051857221871614456, 0.0032203965820372105, 0.02892152965068817, 0.0007886493694968522, 0.011452805250883102, 0.011467845179140568, 0.04869886487722397, 0.034832172095775604, 0.016092583537101746, -0.037358857691287994, 0.005102251190692186, 0.009249475784599781, 0.01979237236082554, 0.010174422524869442, 0.014603642746806145, 0.028680892661213875, 0.019070463255047798, 0.05778289958834648, -0.01044513937085867, 0.05486518144607544, -0.018619269132614136, 0.0009470372460782528, 0.016904732212424278, 0.04138952121138573, 0.030440550297498703, 0.029447922483086586, 0.04683392867445946, -0.007572537753731012, -0.09836027771234512, -0.020664680749177933, -0.03332819044589996, -0.03137301653623581, 0.034832172095775604, 0.0271468348801136, -0.0012097636936232448, 0.011227209120988846, -0.05333112180233002, -0.01206943765282631, 0.00958787091076374, 0.051797062158584595, -0.02525181882083416, -0.01767176203429699, 0.0030267592519521713, 0.007403340190649033, 0.001071585575118661, 0.030500708147883415, -0.005527125671505928, -0.026154207065701485, 0.02057444304227829, -0.024289272725582123, 0.007098784204572439, -0.01622794196009636, 0.004906733985990286, -0.02528189867734909, -0.0016515577444806695, -0.02162722870707512, -0.043465014547109604, -0.04373573139309883, -0.04298374056816101, -0.022168660536408424, 0.04355525225400925, -0.025357097387313843, -0.041720397770404816, 0.057241469621658325, -0.028951609507203102, 0.011467845179140568, 0.006008399184793234, 0.008489965461194515, 0.015731627121567726, -0.03465169295668602, 0.042382147163152695, 0.042412228882312775, 0.046382736414670944, -0.039163630455732346, 0.03027511201798916, 0.003359514754265547, 0.026184286922216415, -0.01373885478824377, -0.015445872209966183, 0.006064798217266798, 0.0028707212768495083, -0.020845159888267517, -0.017175449058413506, 0.06250539422035217, 0.029688559472560883, -0.007993652485311031, 0.0011073050554841757, -0.03033527173101902, -0.037659652531147, 0.02240929752588272, 0.07586073875427246, -0.014723961241543293, 0.025477416813373566, -0.011971678584814072, -0.04187079519033432, 0.01801767759025097, 0.004072024952620268, 0.007903413847088814, 0.00901635829359293, 0.0677994042634964, -0.018243273720145226, 0.023958398029208183, -0.02242433838546276, -0.023672640323638916, 0.003083158517256379, -0.0016421579057350755, 0.01407724991440773, 0.004944333340972662, -0.027688266709446907, -0.004229942802339792, 0.05158650502562523, -0.012986864894628525, 0.010031544603407383, 0.07134880125522614, 0.040246497839689255, -0.011445285752415657, 0.020288687199354172, 0.002966600004583597, -0.011881439946591854, -0.011302407830953598, 0.05348151922225952, -0.0019589336588978767, 0.022589774802327156, -0.019747253507375717, 0.03398994356393814, 0.007042385172098875, -0.020694760605692863, -0.021221153438091278, 0.007192783057689667, -0.00024275173200294375, -0.014475804753601551, -0.008016211912035942, -0.006888227071613073, -0.029673520475625992, -0.006997265852987766, -0.03242580220103264, -0.04337477684020996, 0.05528629571199417, 0.00550456577911973, 0.01497211866080761, 0.0033933543600142, -0.07441692054271698, -0.013099663890898228, -0.00015639039338566363, 0.023281605914235115, -0.05994863063097, 0.016754334792494774, -0.000250976620009169, 0.028710972517728806, 0.04232199117541313, 0.022304018959403038, -0.018153036013245583, 0.029793838039040565, -0.003594511654227972, 0.0019185141427442431, 0.005361687857657671, -0.019596856087446213, 0.008963719010353088, -0.05011260509490967, -0.004406660795211792, -0.02128131315112114, -0.016017384827136993, 0.031222619116306305, 0.006294155027717352, -0.03420050069689751, 0.0004963133251294494, -0.017521364614367485, 0.022484496235847473, 0.00729806162416935, 0.009001318365335464, 0.014235167764127254, -0.016137702390551567, 0.035945113748311996, -0.012152155861258507, 0.02819962054491043, -0.009723229333758354, 0.014611163176596165, -0.023612482473254204, -0.02782362513244152, 0.0270716343075037, -0.023236487060785294, 0.011475365608930588, 0.0006951206596568227, 0.02129635214805603, 0.01657385751605034, -0.02449982985854149, 0.033719226717948914, -0.009888666681945324, -0.03224532678723335, -0.01588202640414238, 0.01982245221734047, -0.018183114007115364, 0.0155361108481884, -0.0069671859964728355, 0.024770546704530716, 0.009129157289862633, 0.007591337896883488, -0.005809121765196323, -0.008933639153838158, -0.0331176333129406, 0.00865540374070406, -0.027297232300043106, 0.006275355350226164, 0.00021972204558551311, -0.029342643916606903, -0.010046584531664848, -0.02853049524128437, 0.0035606720484793186, 0.003974266350269318, -0.017882319167256355, -0.020484203472733498, -0.011836320161819458, -0.0011618243297562003, -0.009610430337488651, 0.011761121451854706, 0.023296646773815155, -0.008911079727113247, -0.002492846455425024, 0.007828214205801487, 0.020694760605692863, -0.05387255549430847, 0.010783534497022629, 0.013287660665810108, -0.03317779302597046, -0.013438059017062187, 0.04773631691932678, -0.012949265539646149, 0.00903891772031784, -0.00658367108553648, 0.01583690568804741, 0.00994882546365261, 0.03149333596229553, -0.00847492553293705, -0.00648967269808054, -0.03495248779654503, -0.05982831493020058, 0.0135734174400568, -0.006989745888859034, 0.001125164795666933, 0.027282191440463066, 0.01049025822430849, -0.01846887171268463, -0.009911226108670235, -0.021085795015096664, -0.001424080808646977, 0.0013676815433427691, -0.03417041897773743, 0.0124379126355052, 0.02304096892476082, -0.003630231134593487, -0.04391620680689812, -0.013656135648488998, -0.011911519803106785, -0.033809464424848557, 0.024815665557980537, -0.0038614680524915457, -0.04000585898756981, -0.017536403611302376, -0.009963865391910076, 0.05062395706772804, 0.003985546063631773, 0.02159714885056019, -0.014859319664537907, -0.008858440443873405, -0.029763758182525635, -0.00668518990278244, -0.003795668948441744, -0.014934518374502659, 0.03787020966410637, -0.02594364993274212, -0.021567068994045258, -0.022965770214796066, 0.012941746041178703, 0.006918306928128004, 0.02640988491475582, -0.012595830485224724, -0.015009718015789986, -0.035554081201553345, 0.0073469411581754684, -0.02159714885056019, 0.019070463255047798, -0.011152009479701519, -0.003534352406859398, 0.02890649065375328, -0.03931403160095215, 0.0012379633262753487, -0.019250940531492233, -0.027161873877048492, 0.01370877493172884, -0.03510288521647453, 0.018574150279164314, 0.035223204642534256, 0.007260462269186974, 0.03567440062761307, 0.029523121193051338, 0.027297232300043106, -0.0390733927488327, -0.017220567911863327, 0.0020510524045675993, -0.00976082868874073, 0.030560867860913277, 0.027898823842406273, 0.004417940508574247, -0.009610430337488651, 0.013031984679400921, -0.014671321958303452, -0.07778583467006683, -0.04042697697877884, 0.04078793153166771, -0.015686508268117905, -0.013423019088804722, 0.002667684108018875, -0.027282191440463066, -0.010061624459922314, 0.04361541196703911, 0.029447922483086586, -0.009888666681945324, -0.03510288521647453, -0.0022747693583369255, -0.0382913239300251, 0.00567752355709672, -0.0338997021317482, 0.006155036855489016, 0.03242580220103264, -0.016348259523510933, -0.01228751428425312, -0.047405440360307693, -0.03239572420716286, 0.010317301377654076, -0.03176405280828476, -0.04163016006350517, -0.02243937738239765, -0.06024942919611931, -0.0012398433173075318, 0.018258314579725266, -0.027507789433002472, 0.03167381137609482, -0.0061211977154016495, 0.002942160237580538, 0.003989306278526783, -0.005820401478558779, -0.009640510194003582, -0.014400606043636799, -0.0425325483083725, 0.01334029994904995, -0.03386962413787842, -0.04078793153166771, 0.004305141977965832, 0.0029008009005337954, 0.0023499683011323214, 0.007956053130328655, 0.0165588166564703, -0.025372138246893883, 0.016378339380025864, 0.04617217928171158, -0.01351325772702694, -0.037749890238046646, -0.002513526240363717, 0.016017384827136993, -0.025823332369327545, 0.012964305467903614, 0.012723668478429317, -0.0011815640609711409, 0.006726549472659826, -0.027989063411951065, 0.009174276143312454, 0.025417257100343704, -0.0009249475551769137, 0.017130328342318535, 0.0005776222096756101, 0.04698432609438896, -0.010242101736366749, -0.01043761894106865, 0.05381239578127861, 0.019957810640335083, -0.02961336076259613, -0.009813467971980572, -0.014911958947777748, 0.007895893417298794, -0.038411643356084824, -0.016423458233475685, 0.04484867677092552, -0.018243273720145226, 0.007895893417298794, -0.0011054250644519925, 0.009535231627523899, 0.010851213708519936, -0.013242541812360287, 0.006309194955974817, -0.0285605750977993, 0.030500708147883415, 0.022890571504831314, -0.016453538089990616, -0.016062503680586815, 0.0009916865965351462, -0.024680307134985924, -0.03793036937713623, -0.028004102408885956, -0.027868743985891342, 0.017897358164191246, 0.006448313128203154, 0.008971239440143108, 0.0022935690358281136, -0.013558377511799335, -0.09029894322156906, -0.029748719185590744, 0.012648469768464565, -0.0037618293426930904, -0.028756093233823776, -0.023341765627264977, 0.01138512697070837, 0.01009922381490469, -0.0198525320738554, -0.008971239440143108, 0.039915621280670166, -0.010941452346742153, 0.012505591847002506, -0.002992919646203518, 0.025522535666823387, -0.045329950749874115, -0.0003701200184877962, -0.04686400666832924, 0.014708921313285828, -0.026830999180674553, -0.008978758938610554, 0.014167489483952522, -0.016062503680586815, 0.007625177036970854, -0.009121636860072613, -0.02164226770401001, -0.014483325183391571, 0.01628809981048107, -0.012911666184663773, -0.017130328342318535, -0.01585194654762745, -0.01083617378026247, -0.005790322087705135, 0.012708628550171852, 0.013295181095600128, 0.0018310953164473176, -0.023386884480714798, -0.012317594140768051, 0.005350407678633928, -0.034140340983867645, 0.01876966655254364, -0.012107037007808685, 0.03693774342536926, -0.03209492564201355, -0.011249768547713757, 0.009685629047453403, 0.025417257100343704, -0.009302115067839622, -0.001627118093892932, 0.0035381123889237642, -0.00046599871711805463, 0.019025344401597977, 0.01807783544063568, -0.016513697803020477, -0.011543044820427895, 0.03221524506807327, -0.036245912313461304, 0.0118889594450593, 0.0055609652772545815, 0.044547878205776215, -0.012340153567492962, -0.0058504813350737095, 0.03573455661535263, -0.01621290110051632, -0.012362712994217873, -0.0007120404043234885, -0.004143464379012585, 0.020078130066394806, -0.01731080748140812, -0.02677083946764469, -0.0008882880210876465, 0.01388925313949585, 0.0331176333129406, 0.037659652531147, 0.002387567888945341, -0.02422911301255226, 0.028259778395295143, 0.017175449058413506, 0.023928318172693253, -0.006707749795168638, 0.0270716343075037, -0.03853195905685425, -0.002953440183773637, 0.029718639329075813, -0.0360955148935318, 0.026439962908625603, -0.026244446635246277, -0.037388935685157776, -0.012580790556967258, 0.03759949281811714, 0.039163630455732346, -0.03859211876988411, -0.015596269629895687, -0.029312564060091972, -0.03937418758869171, -0.039163630455732346, -0.015054836869239807, 0.02920728549361229, 0.04021641984581947, 0.010505298152565956, 0.06719781458377838, 0.019311100244522095, -0.01842375099658966, 0.008617803454399109, 0.01368621550500393, 0.013302700594067574, -0.025718053802847862, 0.00901635829359293, 0.008407246321439743, 0.011136969551444054, 0.002472166670486331, -0.040998488664627075, 0.016498656943440437, 0.012859026901423931, 0.006527272053062916, 0.008377167396247387, 0.037358857691287994, -0.012708628550171852, 0.007331901229918003, -0.001351701794192195, 0.026109088212251663, -0.02776346541941166, -0.026876118034124374, -0.02564285509288311, -0.00695590628311038, 0.042773183435201645, -0.004244982730597258, -0.011054251343011856, -0.029793838039040565, -0.03865227848291397, -0.009813467971980572, 0.010054104961454868, 0.032666441053152084, -0.02928248606622219, 0.017431125044822693, -0.02892152965068817, -0.006324234884232283, -0.012452952563762665, -0.02743259072303772, -0.02989911660552025, -0.0035982714034616947, 0.004993212874978781, -0.007753015495836735, 0.008723082020878792, 0.0015274793840944767, -0.03032023087143898, 0.01043761894106865, -0.005647443700581789, -0.013159822672605515, 0.017130328342318535, -0.019762294366955757, 0.007275501731783152, 0.00035508020664565265, 0.030771424993872643, 0.002126251347362995, 0.013844133354723454, -0.018544070422649384, -0.03549392148852348, -0.006831828039139509, -0.023191368207335472, 0.05011260509490967, 0.005688803270459175, 0.023973437026143074, 0.0346817709505558, 0.03435089811682701, -0.026981396600604057, 0.006339274346828461, -0.005951999686658382, -0.030891744419932365, 0.0005184030160307884, -0.03104214183986187, 8.865255222190171e-05, 0.04575106501579285, -0.0006020618602633476, 0.0324859619140625, 0.02634972520172596, 0.023537281900644302, -0.011866400018334389, 0.00882084108889103, 0.04731520265340805, -0.007151423487812281, 0.02269505336880684, -0.036636944860219955, 0.02344704419374466, -0.0026996436063200235, -0.02052932418882847, -0.00811397098004818, 0.02159714885056019, 0.014611163176596165, -0.03287699818611145, 0.01279886718839407, -0.027628106996417046, -0.0016017383895814419, -0.01624298095703125, 0.005215049721300602, 0.007956053130328655, -0.006873187143355608, -0.013656135648488998, -0.027206992730498314, -0.016453538089990616, -0.03203476965427399, 0.007151423487812281, 0.0077605354599654675, 0.008896039798855782, -0.009881147183477879, 0.052458811551332474, -0.00958787091076374, -0.036997903138399124, -0.010753454640507698, -0.011663362383842468, -0.014167489483952522, -0.019341180101037025, -0.029387764632701874, 0.003906587138772011, -0.010354900732636452, 0.025086382403969765, 0.01873958669602871, 0.035223204642534256, -0.026830999180674553, -0.033689144998788834, -0.00811397098004818, -0.021491870284080505, -0.013731335289776325, -0.0024590068496763706, -0.01624298095703125, 0.022093461826443672, 0.0029402803629636765, 0.012099516578018665, 0.01103921141475439, 0.004538259003311396, -0.020363885909318924, -0.03940426930785179, 0.019732214510440826, 0.004316421691328287, 0.0027974022086709738, 0.0017652962123975158, -0.019205821678042412, 0.020469164475798607, 0.01625801995396614, 0.0017981957644224167, 0.01622794196009636, 0.025823332369327545, 0.011565604247152805, -0.022258900105953217, -0.01428028754889965, 0.02955320104956627, 0.026830999180674553, -0.00594823993742466, 0.035915035754442215, 0.008880999870598316, -0.03423057869076729, 0.02099555730819702, 0.05170682445168495, -0.003786268876865506, 0.030064554885029793, -0.02021348848938942, 0.02316128835082054, 0.035614240914583206, 0.016167782247066498, -0.012828947044909, -0.004929293412715197, 0.0023650082293897867, 0.002966600004583597, -0.025071341544389725, -0.0027071635704487562, -0.01950661651790142, -0.01370877493172884, 0.013987011276185513, 0.00867044273763895, 0.0036095513496547937, 0.017130328342318535, 0.013039504177868366, 0.014949558302760124, 0.02892152965068817, -0.005760242231190205, -0.0006218015914782882, -0.03260628134012222, 0.006703989580273628, 0.023657601326704025, -0.03964490443468094, 0.01046769879758358, 0.009068997576832771, 0.004357781261205673, -0.035163044929504395, 0.03215508535504341, -0.009542751125991344, -0.01952165737748146, 0.007689096499234438, 0.029869036749005318, -0.0001250183122465387, 0.012385273352265358, 0.0036264711525291204, -0.0077605354599654675, -0.005192489828914404, 0.0026000048965215683, -0.005967039614915848, -0.0077680554240942, -0.007170223165303469, -0.00398178631439805, -0.004117144737392664, -0.004899214021861553, 0.0331176333129406, 0.013799013569951057, -0.013483177870512009, 0.04626241698861122, 0.005654963664710522, 0.005587284918874502, -0.03895307332277298, 0.0055572050623595715, -0.008745642378926277, -0.043164219707250595, 0.02848537638783455, 0.03973514586687088, 0.02455998957157135, -0.018874945119023323, -0.010715855285525322, -0.030515749007463455, -0.020845159888267517, 0.023567361757159233, 0.0049104937352240086, -0.004489379469305277, 0.00320723676122725, 0.030515749007463455, 0.02892152965068817, 0.015746667981147766, -0.02774842642247677, 0.02129635214805603, 0.023537281900644302, 0.03245588392019272, 0.014769081026315689, 0.041720397770404816, -0.01622794196009636, 0.027312271296977997, 0.005102251190692186, -0.010151863098144531, -0.021491870284080505, -0.0285605750977993, 0.02022852748632431, 0.015145075507462025, 0.0005748022813349962, -0.007410860154777765, -0.010588017292320728, 0.005215049721300602, 0.021897945553064346, 0.0033764345571398735, -0.006888227071613073, -0.005023292265832424, -0.006974705960601568, 0.0036565507762134075, -0.00229732901789248, 0.0918029248714447, -0.020815080031752586, 0.007301821373403072, 0.01807783544063568, 0.020649641752243042, 0.01100913155823946, -0.013272620737552643, 0.01621290110051632, -0.019025344401597977, -0.006113677751272917, -0.017521364614367485, 0.0070912642404437065, 0.008978758938610554, 0.021912984549999237, 0.025898531079292297, -0.02890649065375328, 2.2956253815209493e-05, -0.058324333280324936, 0.0008582084556110203, -0.009106596931815147, 0.012588310055434704, 0.022093461826443672, -0.012204795144498348, -0.008459885604679585, 0.0005273328861221671, 0.010227061808109283, 0.0016120782820507884, -0.005260169040411711, 0.029056888073682785, 0.007474779151380062, 0.013663656078279018, 0.01027218159288168, -0.013595976866781712, -0.02346208319067955, 0.01913062296807766, 0.02637980505824089, -0.020333806052803993, -0.03032023087143898, -0.006470873020589352, 0.008407246321439743, -0.029177207499742508, -0.020469164475798607, 0.003786268876865506, -0.02021348848938942, 0.04608193784952164, 0.01121216919273138, -0.017596563324332237, -0.03218516707420349, -0.006455833092331886, -0.01229503471404314, -0.035584159195423126, 0.029447922483086586, 0.010745935142040253, 0.02747770957648754, 0.013904293067753315, -0.02057444304227829, -0.02347712405025959, 0.038471803069114685, 0.028064262121915817, -0.00128402269911021, -0.0367271862924099, 0.039163630455732346, -0.02532701939344406, 0.013490698300302029, -0.0346817709505558, -0.01479916088283062, -0.00034756032982841134, 0.0097307488322258, -0.02274017408490181, 0.013656135648488998, -0.01627306081354618, -0.01261087041348219, 0.01535563264042139, -0.02125123329460621, 0.031974609941244125, 0.006632550619542599, 0.015318033285439014, -0.001188143971376121, 0.005940719973295927, 0.008196689188480377, -0.022860491648316383, 0.0006659810314886272, -0.01627306081354618, -0.006745349150151014, 0.002772962674498558, 0.017987597733736038, 0.02089027874171734, 0.008971239440143108, -0.002868841402232647, -0.0006880707223899662, -0.04078793153166771, -0.006132477428764105, 0.029793838039040565, 0.03669710457324982, 0.000871838245075196, -0.0062828753143548965, -0.038381561636924744, 0.011197129264473915, -0.025507496669888496, -0.006023438647389412, -0.0059933592565357685, 0.029808878898620605, -0.01658889651298523, -0.024289272725582123, -0.015318033285439014, -0.025116462260484695, -0.043465014547109604, 0.023973437026143074, -0.01513755600899458, 0.023988476023077965, -0.030094634741544724, 0.015002197585999966, 0.01410732977092266, -0.000659401121083647, 0.005662483628839254, -0.005978319328278303, -0.030440550297498703, 0.031583573669195175, -0.015701549127697945, -0.03943434730172157, 0.03576463833451271, 0.03726861625909805, -0.007519898470491171, 0.016724254935979843, -0.0025830850936472416, -0.01536315307021141, -0.004654817283153534, -0.03224532678723335, 0.004948093090206385, -0.011603203602135181, -0.024379512295126915, 0.025462375953793526, 0.04578114300966263, -0.013626056723296642, -0.006613750942051411, 0.008948679082095623, -0.03134293854236603, -0.01729576662182808, -0.04265286400914192, 0.011693442240357399, -0.005215049721300602, 0.006331754848361015, -0.001076285494491458, -0.027703305706381798, 0.02776346541941166, 0.002562405541539192, 0.004290102049708366, 0.0208752378821373, -0.025011183694005013, 0.006880707107484341, 0.011979199014604092, 0.001951413694769144, 0.04722496494650841, 0.0165588166564703, -0.04141960293054581, -0.020860198885202408, -0.001631818013265729, -0.0439462885260582, -0.0035794717259705067, -0.016694175079464912, 0.01773192174732685, -0.02848537638783455, -0.006779188755899668, 0.0022559696808457375, 0.009347233921289444, 0.005470726173371077, -0.043856047093868256, 0.005764002446085215, 0.00016285281162708998, 0.013874213211238384, -0.01212207693606615, -0.012791347689926624, -0.04650305211544037, 0.007689096499234438, 0.021070756018161774, -0.023341765627264977, 0.003496752819046378, -0.0010029664263129234, -0.01809287630021572, 0.020694760605692863, 0.016814492642879486, -0.014265247620642185, 0.0010349260410293937, 0.007696616463363171, -0.013979491777718067, -0.0032147567253559828, 0.012242395430803299, 0.007971092127263546, -0.01625801995396614, -0.006899506784975529, -0.023537281900644302, -0.02558269537985325, -0.03790028765797615, 0.007538698613643646, 0.014197568409144878, 0.016423458233475685, -0.021807705983519554, -0.02671067975461483, 0.008602764457464218, 0.0069709462113678455, -0.0027861224953085184, -0.003727989736944437, -0.02277025394141674, 0.018905024975538254, 0.006192636676132679, 0.013866692781448364, -0.00901635829359293, -0.025793252512812614, 0.02532701939344406, 0.005346647929400206, -0.017220567911863327, -0.025883492082357407, -0.01228751428425312, -0.014769081026315689, 0.005466966424137354, -0.044608037918806076, 0.020063089206814766, 0.01726568676531315, 0.018213193863630295, -0.02600380964577198, -0.0061174375005066395, 0.01991269178688526, 0.02310112863779068, -0.023928318172693253, -0.0009564370848238468, 0.005670003592967987, 0.026830999180674553, -0.0034159140195697546, 0.0184387918561697, 0.031523413956165314, 0.0031414376571774483, 0.03239572420716286, -0.0007989892037585378, -0.00029515603091567755, -0.0026206846814602613, 0.0009569071116857231, -0.025101421400904655, -0.008204209618270397, 0.003113238140940666, -0.014167489483952522, -0.01152048446238041, 0.04653313383460045, 0.00813653040677309, 0.013287660665810108, -0.01803271658718586, 0.0729730948805809, -0.0188298262655735, 0.004072024952620268, 0.019416378811001778, -0.014287807047367096, -0.0006561111658811569, 0.02304096892476082, -0.020739881321787834, 0.012362712994217873, -0.009632989764213562, -0.010512818582355976, 0.001888434519059956, -0.015400752425193787, -0.042081352323293686, 0.03260628134012222, -0.046773768961429596, -0.007730455603450537, 0.022183701395988464, -0.03579471632838249, 0.02419903315603733, -0.005662483628839254, -0.008144049905240536, 0.005767762195318937, -0.028425216674804688, 0.006572391372174025, 0.03600527346134186, -0.017972556874155998, 0.015002197585999966, -0.020785000175237656, 0.01411485020071268, 0.011558083817362785, 0.021446751430630684, -0.0060121589340269566, -0.006982225924730301, -0.034441135823726654, -0.034080181270837784, 0.007373260799795389, -0.01916070096194744, 0.0002634314587339759, 0.01591210626065731, -0.023552322760224342, -0.04036681726574898, -0.007610137574374676, -0.012039357796311378, -0.010384979657828808, -0.014490844681859016, -0.015017237514257431, 0.017912399023771286, 0.028590654954314232, -0.030771424993872643, 0.01618282124400139, 0.026861077174544334, 0.0013582817045971751, 0.0004439090262167156, 0.008377167396247387, -0.013648616150021553, 0.012941746041178703, 0.01667913608253002, 0.009339714422821999, 0.01583690568804741, 0.028605693951249123, 0.003795668948441744, 0.02307104878127575, 0.0029290004167705774, 0.021747546270489693, 0.004316421691328287, -0.03928394988179207, 0.042111434042453766, -0.013407979160547256, 0.011076810769736767, 0.03708814084529877, -0.02713179402053356, -0.02810938097536564, -0.054684702306985855, -0.021461790427565575, -0.013400459662079811, 0.027974022552371025, 0.04072777181863785, 0.025808291509747505, 0.012016798369586468, 0.010212022811174393, -0.033749304711818695, -1.8373815692029893e-05, 0.011114410124719143, 0.001454160432331264, 0.042081352323293686, 0.03332819044589996, 0.02204834297299385, -0.025462375953793526, 0.016844572499394417, -0.018619269132614136, -0.012550710700452328, -0.006000879220664501, 0.027898823842406273, -0.023958398029208183, 0.029733680188655853, -0.005090971477329731, 0.007155183702707291, 0.0010396259604021907, -0.008384686894714832, 0.006211436353623867, -0.014678842388093472, 0.0052376096136868, -0.012648469768464565, -0.005692563485354185, 0.020815080031752586, 0.019250940531492233, 0.05125562846660614, -0.018889985978603363, -0.027222033590078354, 0.0005517725367099047, -0.006625030655413866, 0.0242441538721323, 0.0159271452575922, 0.01807783544063568, -0.010896333493292332, -0.02308608964085579, -0.020454123616218567, -0.01373885478824377, -0.016904732212424278, 0.02419903315603733, -0.009595390409231186, -0.014543483965098858, -0.00604599853977561, -0.018544070422649384, -0.02455998957157135, 0.0018376752268522978, 0.025041261687874794, -0.00865540374070406, 0.0006490612286143005, -0.01910054311156273, -0.044217005372047424, -0.01765672117471695, -0.013400459662079811, -0.014017091132700443, 0.026259485632181168, -0.023567361757159233, 0.030515749007463455, 0.023582402616739273, 0.023928318172693253, -0.007858294062316418, 0.0009235375327989459, -0.02738747000694275, -0.00956531148403883]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# STEP - 4 : RAG Pipeline with Memory\n",
        "# ============================================\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# --------------------------\n",
        "# 1️ Initialize OpenAI client\n",
        "# --------------------------\n",
        "api_key = userdata.get(\"OPENAI_API_KEY\")  # Load API key from Colab secrets\n",
        "# client = OpenAI(api_key=api_key) # No need to re-initialize client here\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 2️ Initialize OpenAIEmbeddings\n",
        "# --------------------------\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    openai_api_key=api_key\n",
        ")\n",
        "\n",
        "# --------------------------\n",
        "# 3️ Create/Load vector store\n",
        "# --------------------------\n",
        "\n",
        "persist_dir = \"/content/drive/MyDrive/Ironhack_final_project/chromadb_store\" # file path to the vector database\n",
        "\n",
        "vectorstore = Chroma(\n",
        "    persist_directory=persist_dir,  # folder where your vector DB is stored\n",
        "    embedding_function=embeddings\n",
        ")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 4️ Add embedded chunked data to Chromadb_store (vector DB or store)\n",
        "# ----------------------------------------------------------\n",
        "texts = [chunk[\"text\"] for chunk in all_embedded_chunks]\n",
        "metadatas = [\n",
        "    {\n",
        "        \"source\": chunk.get(\"video_id\") or chunk.get(\"article_id\"),\n",
        "        \"chunk_index\": chunk[\"chunk_index\"]\n",
        "    }\n",
        "    for chunk in all_embedded_chunks\n",
        "]\n",
        "\n",
        "# Add documents with automatic embedding generation\n",
        "vectorstore.add_texts(texts=texts, metadatas=metadatas)\n",
        "\n",
        "print(f\"🎉 Done! Chroma vector store is loaded\")\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 5️ Create retriever\n",
        "# --------------------------\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 8})  # higher k for better results\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 6️ LLMChain prompt and chain\n",
        "# --------------------------\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\", \"chat_history\"],\n",
        "    template=\"\"\"\n",
        "You are a helpful AI assistant for content creators.\n",
        "Always answer concisely, clearly, and in a structured format.\n",
        "Prefer bullet points or numbered steps (3–6 items).\n",
        "Each bullet should be 1–2 sentences max.\n",
        "Do not repeat information.\n",
        "If the context is incomplete, use conversation history or your own knowledge.\n",
        "\n",
        "Conversation history:\n",
        "{chat_history}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer (concise and structured):\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "# prompt = PromptTemplate(\n",
        "#     input_variables=[\"context\", \"question\", \"chat_history\"],\n",
        "#     template=\"\"\"\n",
        "# You are a helpful AI assistant. Use the context below and the chat history to answer the question.\n",
        "# If the context is incomplete, rely on conversation history or your knowledge to give the best answer.\n",
        "\n",
        "# Conversation history:\n",
        "# {chat_history}\n",
        "\n",
        "# Context:\n",
        "# {context}\n",
        "\n",
        "# Question: {question}\n",
        "\n",
        "# Answer:\n",
        "# \"\"\"\n",
        "# )\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3, openai_api_key=api_key) # Pass the api_key here\n",
        "\n",
        "\n",
        "# ----------------------\n",
        "# Add memory here\n",
        "# ----------------------\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "\n",
        "qa_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "\n",
        "# ----------------------------------\n",
        "# 7️ Full RAG function with memory\n",
        "# ----------------------------------\n",
        "\n",
        "def ask_rag(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Full RAG pipeline: retrieves relevant chunks, uses memory, and generates answer.\n",
        "    \"\"\"\n",
        "    # --- Retrieve relevant chunks ---\n",
        "    results = retriever.get_relevant_documents(query)\n",
        "\n",
        "    if not results:\n",
        "        return \"❌ No relevant documents found.\"\n",
        "\n",
        "    # --- Combine retrieved chunks ---\n",
        "    context = \"\\n\\n\".join([doc.page_content for doc in results])\n",
        "\n",
        "    print(\"\\n📝 Retrieved context preview:\\n\", context[:1000])\n",
        "\n",
        "    # --- Load memory ---\n",
        "    chat_history = memory.load_memory_variables({}).get(\"chat_history\", [])\n",
        "\n",
        "    # --- Generate answer ---\n",
        "    answer = qa_chain.run({\n",
        "        \"context\": context,\n",
        "        \"question\": query,\n",
        "        \"chat_history\": chat_history\n",
        "    })\n",
        "\n",
        "    # --- Save interaction into memory ---\n",
        "    memory.save_context({\"input\": query}, {\"output\": answer})\n",
        "\n",
        "    return answer"
      ],
      "metadata": {
        "id": "BRh5r9OIJlye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31734ef3-d1dc-4dc6-920c-2c118494647d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1257009309.py:24: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embeddings = OpenAIEmbeddings(\n",
            "/tmp/ipython-input-1257009309.py:35: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
            "  vectorstore = Chroma(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉 Done! Chroma vector store is loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1257009309.py:116: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
            "/tmp/ipython-input-1257009309.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  qa_chain = LLMChain(llm=llm, prompt=prompt)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ✅ Run a memory test\n",
        "print(\"\\n--- Memory Test ---\\n\")\n",
        "\n",
        "# First interaction\n",
        "response1 = ask_rag(\"My name is Abhi.\")\n",
        "print(\"User: My name is Abhi.\")\n",
        "print(\"Bot:\", response1)\n",
        "\n",
        "# Second interaction (checks memory)\n",
        "response2 = ask_rag(\"What is my name?\")\n",
        "print(\"\\nUser: What is my name?\")\n",
        "print(\"Bot:\", response2)\n",
        "\n",
        "# Third interaction (longer context test)\n",
        "response3 = ask_rag(\"Remember that I like working with RAG pipelines.\")\n",
        "print(\"\\nUser: Remember that I like working with RAG pipelines.\")\n",
        "print(\"Bot:\", response3)\n",
        "\n",
        "response4 = ask_rag(\"What do I like working with?\")\n",
        "print(\"\\nUser: What do I like working with?\")\n",
        "print(\"Bot:\", response4)\n"
      ],
      "metadata": {
        "id": "utvaf9F5G1rB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c833c52-d5f5-44de-ff2b-81e7006bcd6e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Memory Test ---\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1257009309.py:131: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  results = retriever.get_relevant_documents(query)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📝 Retrieved context preview:\n",
            " AI to do the work for you thank you so much for watching the video and I'll see you in next one\n",
            "\n",
            "AI to do the work for you thank you so much for watching the video and I'll see you in next one\n",
            "\n",
            "AI to do the work for you thank you so much for watching the video and I'll see you in next one\n",
            "\n",
            "AI to do the work for you thank you so much for watching the video and I'll see you in next one\n",
            "\n",
            "AI to do the work for you thank you so much for watching the video and I'll see you in next one\n",
            "\n",
            "AI to do the work for you thank you so much for watching the video and I'll see you in next one\n",
            "\n",
            "AI to do the work for you thank you so much for watching the video and I'll see you in next one\n",
            "\n",
            "AI to do the work for you thank you so much for watching the video and I'll see you in next one\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1257009309.py:145: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  answer = qa_chain.run({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: My name is Abhi.\n",
            "Bot: - Nice to meet you, Abhi!\n",
            "- How can I assist you today?\n",
            "- Feel free to ask any questions or request help with your content creation.\n",
            "\n",
            "📝 Retrieved context preview:\n",
            " is a great option. Start with a prompt (like “Short-form social media video about financial literacy,” and watch as your video comes to life. You can then make changes to the video’s language, content, and more through additional text prompts. Create bite-sized video content in minutes, perfect for small teams who can’t rely on video production. Source: Invideo Use Invideo for: However, it’s not best for: Canva is a well-known online graphics editing app that has, in recent years, expanded to cover document design, presentations, mini websites, and more. Like other apps, Canva has added a slew of AI-powered content creation features over the last year, which they call “Magic Design.” Upload any existing media and Magic Design will give you matching templates, like social media templates, quote graphics, documents, and more. This makes it super fast to repurpose content across different platforms in a way that still optimizes each platform’s strength. Magic Design also works with text p\n",
            "\n",
            "User: What is my name?\n",
            "Bot: - Your name is Abhi.\n",
            "\n",
            "📝 Retrieved context preview:\n",
            " preset Style cinematic the contrast on medium generation mode fast image Dimension 16x9 let's do medium and four Images here now I'm going to prompt it the same prompt we've done with the mechanical tiger this will cost us 24 credits I'll just click on generate and here are the results here you can see the result number one it's decent here's result number two I don't like this right paw here here is the result number three again it is very grainy it seems like it's raining but it's still very very grainy and this one as well the proportions aren't really correct if we compare this with flux through Korea AI you obviously see a different story just so much cleaner you can see the texture on the armor while here it's more of a drawing sketch of something that doesn't look as good let's try another prompt like the fairy living inside a glass bottle this is the result we got and yeah just looking at her face the eyes don't have the clarity and everything like that doesn't even look like t\n",
            "\n",
            "User: Remember that I like working with RAG pipelines.\n",
            "Bot: - **RAG Overview**: RAG (Retrieval-Augmented Generation) combines retrieval of relevant documents with generative models to enhance content creation.\n",
            "- **Pipeline Steps**:\n",
            "  1. **Input Query**: Start with a user query or prompt that requires information.\n",
            "  2. **Document Retrieval**: Use a search engine or database to fetch relevant documents or data based on the query.\n",
            "  3. **Content Generation**: Input the retrieved documents into a generative model (like GPT) to create a coherent response.\n",
            "  4. **Output Refinement**: Review and edit the generated content for clarity and relevance.\n",
            "  5. **Feedback Loop**: Incorporate user feedback to improve future retrieval and generation processes.\n",
            "- **Benefits**: This approach enhances accuracy, provides diverse perspectives, and improves the quality of generated content.\n",
            "\n",
            "📝 Retrieved context preview:\n",
            " does image and video, Google Veo 3 and Flow, which is video, MidJourney, which is image, and 11 Labs, which is sound effects. And I went through a couple different combinations of workflows that you could try with those. Again, right now, my life is firmly planned at this intersection, AI tools and content strategy. My only goal is to build the best tools, the best systems, the best information to help you figure out how to use content to grow your business and make AI workflows that allow you to make content easier, faster, better. So, if you want me to make more videos like this that are a little bit more focused on AI instead of the theoretical content stuff, please leave a comment and let me know and I can start doing that. And remember, ton of free stuff in the description. Just check it out. There's so many links. I'm just giving away the answers. If you have this problem, check it out in the description. All right, we'll see you guys on the next one. Peace.\n",
            "\n",
            "does image and video\n",
            "\n",
            "User: What do I like working with?\n",
            "Bot: - You like working with RAG (Retrieval-Augmented Generation) pipelines.\n",
            "- You focus on AI tools and content strategy.\n",
            "- You aim to build effective systems and workflows for content creation.\n",
            "- You utilize various AI tools, including Google Veo 3, Flow, MidJourney, and 11 Labs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# STEP - 5 :  Testing my RAG retrieval and its memory with multiple questions\n",
        "# =============================================================================\n",
        "\n",
        "# First question: sets some context\n",
        "print(ask_rag(\"What is an AI image generator?\"))\n",
        "\n",
        "# Second question: relies on memory\n",
        "print(ask_rag(\"And which one is considered the best?\"))\n",
        "\n",
        "# Third question: continues from memory\n",
        "print(ask_rag(\"Why is it considered the best?\"))\n",
        "\n",
        "\n",
        "# # -----------------------\n",
        "# # 8️⃣ Testing my RAG\n",
        "# # -----------------------\n",
        "# if __name__ == \"__main__\":\n",
        "#     user_query = input(\"❓ Enter your question: \")\n",
        "#     answer = ask_rag(user_query)\n",
        "#     print(\"\\n💡 Answer:\\n\", answer)\n",
        "\n",
        "\n",
        "# # -----------------------------------------------------------\n",
        "# # 8️⃣ Testing RAG with memory with continuous questioning\n",
        "# # -----------------------------------------------------------\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     print(\"📝 You can ask multiple questions. Type 'exit' to quit.\\n\")\n",
        "\n",
        "#     while True:\n",
        "#         user_query = input(\"❓ Enter your question: \")\n",
        "#         if user_query.lower() in [\"exit\", \"quit\"]:\n",
        "#             print(\"👋 Exiting chat. Goodbye!\")\n",
        "#             break\n",
        "\n",
        "#         answer = ask_rag(user_query)\n",
        "#         print(\"\\n💡 Answer:\\n\", answer)\n",
        "#         print(\"-\" * 50)  # separator for readability\n",
        "\n"
      ],
      "metadata": {
        "id": "l242PpnfJlwQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc88180-a225-4f40-9b2f-ae1c1cf9b466"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📝 Retrieved context preview:\n",
            " AI has revolutionized image creation. You can now type in a text prompt, like design a storefront for a cookie store, and get captivating visuals back. There are lots of different AI image generators out there, both free and also paid, and you've probably used some yourself. In this video, in partnership with Zapier, we'll look at the top seven AI image generators from Dalle 3 to Midjourney and more. Let's dive in. First up, we have Dalle 3, which is developed by OpenAI, the maker of ChatGPT. You can access this directly from chatgpt.com with a free account, although you only get two images per day. With a plus account, on the other hand, you can create more images, but plans start at $20 per month. As an alternative, you can go to Microsoft's Bing Image Creator, which allows you to create any number of images for free, and it uses Dalle 3 on the backend, the same as what you get with ChatGPT. So, what do I like or dislike about it? Well, overall, you get highly detailed and realistic \n",
            "- **Definition**: An AI image generator is a software tool that creates images based on text prompts using artificial intelligence algorithms.\n",
            "- **Functionality**: Users input descriptive text, and the AI interprets it to produce unique visual content.\n",
            "- **Types**: There are various types of AI image generators, including those that focus on realism, artistic styles, or specific themes.\n",
            "- **Applications**: These tools are used in fields like marketing, design, entertainment, and content creation to generate visuals quickly and efficiently.\n",
            "- **Examples**: Popular AI image generators include DALL-E, Midjourney, and Stable Diffusion.\n",
            "\n",
            "📝 Retrieved context preview:\n",
            " pretty good, but what do I not like? It's very resource intensive, so you'll need a powerful computer to be able to run it, which could be a limitation. Last up at number seven, we have Generative AI by Getty Images, which was developed in partnership with NVIDIA. This is by far the most expensive of all the offerings, starting at $49 for just 25 image generations. So why would you use this? Well, all the images are legally secure and commercially safe. The AI was trained on Getty Images' vast library of images, but as large as their archive is, it's not as large as what many of the options we looked at used. Also, they offer fewer customization options compared to some of the open-source alternatives, which can restrict your creativity. So, there you have it, some of the best AI generators out there, each with its own strengths and also weaknesses. Which one are you most excited about to try? And did you learn about any new ones? Let me know in the comments. Please consider subscribin\n",
            "- **Best AI Image Generator**: The \"best\" AI image generator often depends on specific needs and preferences.\n",
            "- **DALL-E**: Known for its versatility and ability to generate high-quality images from detailed prompts.\n",
            "- **Midjourney**: Popular for artistic styles and creative outputs, favored by designers and artists.\n",
            "- **Stable Diffusion**: An open-source alternative that allows for extensive customization and flexibility.\n",
            "- **Generative AI by Getty Images**: Offers legally secure images but is expensive and less customizable.\n",
            "- **Recommendation**: Evaluate based on your requirements, such as quality, cost, and customization options.\n",
            "\n",
            "📝 Retrieved context preview:\n",
            " absolutely insane just look at the quality of the wrinkles in the forehead the eyes as well as the teeth having this shine on them so if I wanted to generate an image with them all I need to do is write a text description in the bottom I want to do one of my favorite styles of all time inside of CG dream I'll make the prompt super simple and then I'll apply some of my favorite filters called abstract 3D fractals and I'll basically just search for fractals and and apply this Coral filter as well as many other abstract filters then I'll go in here and I'll actually put the corals at A1 and all the other ones on 50% and then let's generate I'm going to generate four at a time and here you can see the results just look at the extreme detail of the face with all the pores look at the crown and the patterns that are imprinted and made out of just kind of takes me back to the Renaissance days here we have the other examples as well wow I just really love this style and I only been able to do \n",
            "- **Quality of Output**: CG Dream produces highly detailed and visually appealing images, showcasing intricate features like wrinkles and textures.\n",
            "- **User-Friendly**: It offers a simple interface, making it accessible for beginners who may not want to write complex prompts.\n",
            "- **Credit System**: Users receive 3,000 monthly credits, allowing for substantial image generation without immediate costs.\n",
            "- **Customization Options**: The platform supports various filters, such as abstract 3D fractals, enhancing creative control over the generated images.\n",
            "- **Community Feedback**: The ability to generate images quickly and efficiently has led to positive user experiences, reinforcing its reputation as a top choice.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**==================>>> T O O L S <<<========================**"
      ],
      "metadata": {
        "id": "5ZHn7ePsqqC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# STEP - 6 : Retriever tool (Chroma retriever) with metadata\n",
        "# ============================================\n",
        "\n",
        "from langchain.tools import Tool\n",
        "\n",
        "retriever_tool = Tool(\n",
        "    name=\"Chroma Retriever\",\n",
        "    func=vectorstore.as_retriever().get_relevant_documents,\n",
        "    description=(\n",
        "        \"This is the PRIMARY tool to use first. \"\n",
        "        \"Always try this before using any other tool. \"\n",
        "        \"It retrieves relevant document chunks from the Chroma database \"\n",
        "        \"to answer questions when the context exists.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"✅ Retriever tool is loaded\")"
      ],
      "metadata": {
        "id": "vBAeCTMwJlt-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e19eb6e7-2ba5-49cd-81de-38922abc7e7f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Retriever tool is loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# STEP - 7 : Google Search tool (Tavily)\n",
        "# ============================================\n",
        "\n",
        "\n",
        "# from langchain.tools import Tool\n",
        "\n",
        "\n",
        "tavily_api_key = userdata.get('TAVILY_API_KEY')\n",
        "if not tavily_api_key:\n",
        "    raise ValueError(\"❌ No Tavily API key found! Please add it in Colab secrets.\")\n",
        "\n",
        "from tavily import TavilyClient\n",
        "tavily = TavilyClient(api_key=tavily_api_key)\n",
        "\n",
        "def search_tavily(query: str):\n",
        "    \"\"\"Perform a web search using Tavily and return top results as a list.\"\"\"\n",
        "    results = tavily.search(query, max_results=3)\n",
        "    # Return a list of result content\n",
        "    return [r[\"content\"] for r in results[\"results\"]]\n",
        "\n",
        "search_tool = Tool(\n",
        "    name=\"Google Search (Tavily)\",\n",
        "    func=search_tavily,\n",
        "    description=\"Use this when the question cannot be answered from the context. Returns top 3 web search results.\"\n",
        ")\n",
        "\n",
        "print(\"✅ Search tool is loaded\")\n",
        "\n",
        "# ------------------------------------\n",
        "# Testing the search tool (Tavily)\n",
        "# ------------------------------------\n",
        "\n",
        "results = search_tavily(\"AI image generators\")\n",
        "print(f\"🔍 Tavily Search Results:\")\n",
        "for i, r in enumerate(results, 1):\n",
        "    print(f\" {i}. {r}\")"
      ],
      "metadata": {
        "id": "CflNew8NYuWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90407167-9949-4c86-a71e-5a0a7c1b800a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Search tool is loaded\n",
            "🔍 Tavily Search Results:\n",
            " 1. DeepAI's Free Online AI Image Generator gives you the power to visualize your imagination in seconds. Just describe your vision and watch it come to life.\n",
            " 2. * Canva’s AI image generators are available with limited use on Free accounts. * Canva’s AI image generator tools make it easy to turn text into visuals. Please be mindful that Canva doesn’t guarantee that the AI-generated images, designs, and text you generate are cleared for use (particularly if the image or design you create looks like someone else’s work). Between you and Canva, you own the designs you generate with our AI image generators, which is subject to you following our Terms. We’ve put layers of safety measures in place so you can use Magic Media's Text to Image tool, our free AI image generator from text, safely and responsibly.\n",
            " 3. ## ImagineArt AI Generated Images ## All The Features That You Need In An AI Image Generator Tool ## What Makes Us The Best AI Image Generator? Having multiple options ensures that your AI-generated images match your creative style perfectly. Generate AI Image ## How To Make AI Generated Images ## Explore Imagine AI image Generator Tools Image Studio by ImagineArt stands out as one of the best free AI image generators available. Yes, Image Studio allows users to generate AI images without any watermark, even on the free plan. A good AI image generator like Image Studio offers a combination of high-quality models, flexible customization, intuitive tools, and speed. ImagineArt is the best AI Image generator!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# STEP 8 - W H I S P E R  T O O L - for Speech-to-Text\n",
        "# ========================================================\n",
        "\n",
        "# import whisper # Removed this import\n",
        "# import sounddevice as sd # Keep this import if local recording is desired, but address PortAudio issue separately\n",
        "from scipy.io.wavfile import write\n",
        "from langchain.tools import Tool\n",
        "from openai import OpenAI # Ensure OpenAI client is imported\n",
        "\n",
        "# Load Whisper model once # Removed this line\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "\n",
        "def record_audio(filename=\"input.wav\", duration=5, fs=16000):\n",
        "    print(f\"🎤 Recording for {duration} seconds...\")\n",
        "    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1)\n",
        "    sd.wait()\n",
        "    write(filename, fs, audio)\n",
        "    print(\"✅ Recording finished\")\n",
        "    return filename\n",
        "\n",
        "def transcribe_audio_openai(audio_file_path):\n",
        "    \"\"\"Transcribes audio using OpenAI's Whisper model.\"\"\"\n",
        "    with open(audio_file_path, \"rb\") as audio_file:\n",
        "        # Use the existing 'client' object from cell oz4C828MYuR5\n",
        "        # Make sure the client is initialized in a preceding cell\n",
        "        transcription = client.audio.transcriptions.create(\n",
        "            model=\"whisper-1\", # OpenAI's Whisper model\n",
        "            file=audio_file\n",
        "        )\n",
        "    return transcription.text\n",
        "\n",
        "# --- Wrap in a Tool ---\n",
        "def whisper_speech_to_text(audio_file_path):\n",
        "    \"\"\"Transcribes a given audio file into text using OpenAI's Whisper.\"\"\"\n",
        "    # Note: This now expects a file path as input, not live recording due to PortAudio issue\n",
        "    # If local recording is resolved, you can add logic here to record first\n",
        "    if not os.path.exists(audio_file_path):\n",
        "         return f\"❌ Error: Audio file not found at {audio_file_path}\"\n",
        "\n",
        "    text = transcribe_audio_openai(audio_file_path)\n",
        "    return text\n",
        "\n",
        "whisper_tool = Tool(\n",
        "    name=\"Whisper Speech-to-Text\",\n",
        "    func=whisper_speech_to_text,\n",
        "    description=(\n",
        "        \"Transcribes an audio file (provide file path) into text using OpenAI's Whisper model. \"\n",
        "        # Removed the part about recording live audio due to environment limitations\n",
        "        \"Useful for converting spoken content from a file into text for analysis or response generation.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"✅ Whisper tool is loaded (using OpenAI)\")"
      ],
      "metadata": {
        "id": "Gans4It3YuUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a2d634-18b9-484d-9f0b-0124d0825acf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Whisper tool is loaded (using OpenAI)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# STEP - 9 : TTS (Text-to-Speech) tool with OpenAI\n",
        "# =====================================================\n",
        "\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "\n",
        "# client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "def text_to_speech(text, filename=\"response.mp3\"):\n",
        "    \"\"\"\n",
        "    Convert agent's text response to natural speech using OpenAI TTS\n",
        "    \"\"\"\n",
        "    with client.audio.speech.with_streaming_response.create(\n",
        "        model=\"gpt-4o-mini-tts\",   # You can also try \"gpt-4o-tts\" for higher quality\n",
        "        voice=\"alloy\",             # Options: alloy, verse, sage, etc.\n",
        "        input=text,\n",
        "    ) as response:\n",
        "        response.stream_to_file(filename)\n",
        "\n",
        "    print(f\"🔊 Saved speech to {filename}\")\n",
        "    return filename\n",
        "\n",
        "# Wrap text-to-speech function as a Tool\n",
        "tts_tool = Tool(\n",
        "    name=\"Text-to-Speech\",\n",
        "    func=text_to_speech,\n",
        "    description=\"Converts text into natural-sounding speech using OpenAI TTS and saves as MP3.\"\n",
        ")\n",
        "\n",
        "print(\"✅ Text-to-Speech tool is loaded\")"
      ],
      "metadata": {
        "id": "oz4C828MYuR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc2464d-204f-4eac-b25e-8ec7818279ef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Text-to-Speech tool is loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================\n",
        "# STEP - 10 : N E W S  T O O L - Powered by Google\n",
        "# =================================================\n",
        "\n",
        "import os\n",
        "from langchain.utilities import SerpAPIWrapper\n",
        "from langchain.agents import Tool\n",
        "\n",
        "# --------------------------\n",
        "# 1️⃣ Load SerpAPI key\n",
        "# --------------------------\n",
        "# For Colab, you can use userdata.get() if available\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    serpapi_api_key = userdata.get('SERPAPI_API_KEY')\n",
        "except ImportError:\n",
        "    serpapi_api_key = os.getenv('SERPAPI_API_KEY')\n",
        "\n",
        "if not serpapi_api_key:\n",
        "    raise ValueError(\"❌ No SerpAPI API key found! Please set it in environment variables or Colab secrets.\")\n",
        "\n",
        "os.environ['SERPAPI_API_KEY'] = serpapi_api_key\n",
        "\n",
        "# --------------------------\n",
        "# 2️⃣ Initialize SerpAPI wrapper\n",
        "# --------------------------\n",
        "search = SerpAPIWrapper()  # automatically uses SERPAPI_API_KEY\n",
        "\n",
        "# --------------------------\n",
        "# 3️⃣ Safe search function\n",
        "# --------------------------\n",
        "def safe_news_search(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Searches the web using SerpAPI and returns a concise summary of the top results.\n",
        "\n",
        "    Args:\n",
        "        query (str): The search query. Must not be empty.\n",
        "\n",
        "    Returns:\n",
        "        str: Concise summary of the search results or an error message if input is invalid.\n",
        "    \"\"\"\n",
        "    if not query or query.strip() == \"\":\n",
        "        return \"❌ Cannot perform search: the query is empty.\"\n",
        "\n",
        "    # Get top 5 results for brevity\n",
        "    results = search.results(query)\n",
        "    organic = results.get(\"organic_results\", [])\n",
        "\n",
        "    if not organic:\n",
        "        return \"No results found for your query.\"\n",
        "\n",
        "    summary_lines = []\n",
        "    for i, r in enumerate(organic[:5], 1):\n",
        "        title = r.get(\"title\", \"No title\")\n",
        "        link = r.get(\"link\", \"No link\")\n",
        "        snippet = r.get(\"snippet\", \"\")\n",
        "        summary_lines.append(f\"{i}. {title}\\n   {snippet}\\n   🔗 {link}\")\n",
        "\n",
        "    return \"\\n\\n\".join(summary_lines)\n",
        "\n",
        "# --------------------------\n",
        "# 4️⃣ Wrap as a LangChain tool\n",
        "# --------------------------\n",
        "news_tool = Tool(\n",
        "    name=\"Latest AI News\",\n",
        "    func=safe_news_search,\n",
        "    description=(\n",
        "        \"Use this tool to search the web for factual information, news, or updates on a specific topic. \"\n",
        "        \"Only call it when the user asks a factual question or requests the latest news. \"\n",
        "        \"Do NOT use it for greetings, casual conversation, or personal opinions. \"\n",
        "        \"The input must be a valid search query; empty queries will return an error.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"✅ Latest AI News tool is loaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHbtslgLJreG",
        "outputId": "d17daf4f-f54a-409d-9efa-94405c0d87dc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Latest AI News tool is loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b1dd1bc",
        "outputId": "2a8841d8-fc6a-4356-d146-9959ed723320"
      },
      "source": [
        "!pip install fpdf"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=78e2769df686971a6f1d7bff84a0380ab4e9b32d485c3d6e8d8a0d50fe5be1a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/62/11/dc73d78e40a218ad52e7451f30166e94491be013a7850b5d75\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# STEP - 11 : SAVE CHAT AS PDF TOOL\n",
        "# ============================================\n",
        "\n",
        "from fpdf import FPDF\n",
        "\n",
        "def save_chat_as_pdf(chat_text: str, filename=\"chat.pdf\"):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    pdf.multi_cell(0, 10, chat_text)\n",
        "    pdf.output(filename)\n",
        "    return f\"Chat saved to {filename}\"\n",
        "\n",
        "from langchain.agents import Tool\n",
        "\n",
        "save_pdf_tool = Tool(\n",
        "    name=\"SaveChatPDF\",\n",
        "    func=save_chat_as_pdf,\n",
        "    description=\"Saves the current chat as a PDF file.\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "pLr0LWHFAOU1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# STEP - 11 : SUMMARY TOOL\n",
        "# ============================================\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def summarize_url(url: str):\n",
        "    res = requests.get(url)\n",
        "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "    text = soup.get_text()\n",
        "    # Use your LLM to summarize\n",
        "    summary = llm.predict(f\"Summarize this text:\\n{text}\")\n",
        "    return summary\n",
        "\n",
        "url_summary_tool = Tool(\n",
        "    name=\"URLSummary\",\n",
        "    func=summarize_url,\n",
        "    description=\"Reads a URL and returns a summarized version of its content.\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "tRkdIVaQAvrz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# STEP - 11 : GREETING TOOL\n",
        "# ============================================\n",
        "import random\n",
        "\n",
        "\n",
        "def greet_user(user_input: str = None) -> str:\n",
        "    greetings_general = [\n",
        "        \"Hello! 👋 I’m your AI Content Coach. How can I assist you today?\",\n",
        "        \"Hi there! I’m here to help you create amazing content. What would you like to work on?\",\n",
        "        \"Hey! Ready to improve your content? Let’s get started.\",\n",
        "        \"Hello! I can guide you through content creation, AI tools and tips. What’s first?\"\n",
        "    ]\n",
        "\n",
        "    if user_input:\n",
        "        user_input_lower = user_input.lower()\n",
        "        if any(word in user_input_lower for word in [\"morning\", \"afternoon\", \"evening\"]):\n",
        "            time_word = next((w for w in [\"morning\", \"afternoon\", \"evening\"] if w in user_input_lower), \"day\")\n",
        "            return f\"Good {time_word.capitalize()}! I’m your AI Content Coach. How can I help you today?\"\n",
        "        if any(word in user_input_lower for word in [\"hi\", \"hello\", \"hey\"]):\n",
        "            return random.choice(greetings_general)\n",
        "\n",
        "    return random.choice(greetings_general)\n",
        "\n",
        "greeting_tool = Tool(\n",
        "    name=\"Greeting\",\n",
        "    func=greet_user,\n",
        "    description=\"Responds naturally to greetings like 'hi', 'hello', or 'good morning'.\"\n",
        ")\n",
        "\n",
        "\n",
        "print(\"✅ Greeting tool is loaded\")"
      ],
      "metadata": {
        "id": "y5AkdBTAYuNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f308a247-c9ea-4227-e0e7-69b6ea6c2c90"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Greeting tool is loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**=================== > > > AGENT < < < ======================**"
      ],
      "metadata": {
        "id": "eqS_H3qF5Ndr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# STEP - 12 : Conversational A G E N T\n",
        "# ============================================\n",
        "\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import Tool\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio, display\n",
        "import openai\n",
        "# import sounddevice as sd\n",
        "import numpy as np\n",
        "import tempfile\n",
        "import wave\n",
        "\n",
        "\n",
        "# ----------------------------------------\n",
        "# Integrating list of tools to the Agent\n",
        "# ----------------------------------------\n",
        "\n",
        "tools = [greeting_tool, retriever_tool, search_tool, whisper_tool, news_tool, tts_tool, save_pdf_tool, url_summary_tool]\n",
        "\n",
        "# ------------------------------------\n",
        "# 3️⃣ Initialize Agent with Memory\n",
        "# ------------------------------------\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    memory=memory,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")\n",
        "\n",
        "print(\"🤖 AI Content Coach is ready! Type 'exit' to quit.\")\n",
        "\n",
        "# --------------------------\n",
        "# 4️⃣ Run Conversation Loop\n",
        "# --------------------------\n",
        "\n",
        "voice_enabled = False  # 🔇 Default OFF\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"\\nYou: \")\n",
        "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"👋 Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Toggle voice manually\n",
        "    if user_input.lower() == \"voice on\":\n",
        "        voice_enabled = True\n",
        "        print(\"🔊 Voice enabled.\")\n",
        "        continue\n",
        "    elif user_input.lower() == \"voice off\":\n",
        "        voice_enabled = False\n",
        "        print(\"🔇 Voice disabled.\")\n",
        "        continue\n",
        "\n",
        "    # Agent responds\n",
        "    response = agent.run(user_input)\n",
        "    print(\"\\nAI:\", response)\n",
        "\n",
        "    # Play audio only if enabled\n",
        "    if voice_enabled:\n",
        "        text_to_speech(response)"
      ],
      "metadata": {
        "id": "G2Pkc23sYuK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dedd3cb-f1f4-475e-8f5f-6d673d8a59cb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2266210974.py:26: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 AI Content Coach is ready! Type 'exit' to quit.\n",
            "\n",
            "You: quit\n",
            "👋 Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**=================== > > > AGENT DEPLOYMENT < < < ======================**"
      ],
      "metadata": {
        "id": "sdWdFyfiTEDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s38lTjpkkl7T",
        "outputId": "def45e18-2fb4-4f59-f767-7cd21268cebe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gradio as gr\n",
        "import os\n",
        "import inspect, asyncio, traceback, tempfile, logging, types\n",
        "import markdown\n",
        "\n",
        "# Path for logs\n",
        "LOG_FILE = \"agent_gradio.log\"\n",
        "logging.basicConfig(filename=LOG_FILE,\n",
        "                    level=logging.INFO,\n",
        "                    format=\"%(asctime)s %(levelname)s %(message)s\")\n",
        "\n",
        "# ----------------- Globals -----------------\n",
        "voice_enabled = False\n",
        "\n",
        "\n",
        "def should_use_retriever(query: str) -> bool:\n",
        "    \"\"\"Decide if query needs external knowledge (RAG) or just memory.\"\"\"\n",
        "    conversational_keywords = [\"my name\", \"what did i say\", \"remember\", \"earlier\", \"last time\"]\n",
        "    return not any(keyword in query.lower() for keyword in conversational_keywords)\n",
        "\n",
        "\n",
        "# ----------------- Core RAG Agent Logic -----------------\n",
        "\n",
        "def chat_with_agent(message, history):\n",
        "    user_query = message.strip()\n",
        "\n",
        "    # Convert chat_history (list of tuples) into OpenAI message format\n",
        "    messages = [{\"role\": \"system\", \"content\": \"You are a helpful AI assistant. \"\n",
        "            \"Always keep responses short, concise, and informative. \"\n",
        "            \"Limit answers to 2–5 sentences or bullet points.\"}]\n",
        "    for user_msg, bot_msg in history:\n",
        "        messages.append({\"role\": \"user\", \"content\": user_msg})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": bot_msg})\n",
        "\n",
        "    # Add the latest user query\n",
        "    messages.append({\"role\": \"user\", \"content\": user_query})\n",
        "\n",
        "    try:\n",
        "        if should_use_retriever(user_query):\n",
        "            # ✅ Use RAG pipeline (retriever + memory)\n",
        "            response = ask_rag(user_query)\n",
        "        else:\n",
        "            # ✅ Use memory only (skip retriever)\n",
        "            completion = client.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=messages,\n",
        "                max_tokens=250\n",
        "            )\n",
        "            response = completion.choices[0].message.content\n",
        "\n",
        "    except Exception as e:\n",
        "        response = f\"⚠️ Agent Error: {str(e)}\"\n",
        "\n",
        "    return response\n",
        "\n",
        "\n",
        "\n",
        "# ----------------- Feature Functions -----------------\n",
        "def text_to_speech(text):\n",
        "    \"\"\"Placeholder function to simulate text-to-speech.\"\"\"\n",
        "    print(f\"Simulating TTS for: '{text}'\")\n",
        "    # In a real app, you would use a library like gTTS or pyttsx3.\n",
        "    # from gtts import gTTS\n",
        "    # tts = gTTS(text=text, lang='en')\n",
        "    # tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\")\n",
        "    # tts.save(tmp.name)\n",
        "    # return tmp.name\n",
        "    return None # Returns None to indicate no audio file is produced in this example\n",
        "\n",
        "def download_transcript(history):\n",
        "    \"\"\"Placeholder function to download chat transcript.\"\"\"\n",
        "    path = tempfile.NamedTemporaryFile(delete=False, suffix=\".txt\").name\n",
        "    try:\n",
        "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "            for user, assistant in history:\n",
        "                f.write(\"User: \" + str(user) + \"\\n\")\n",
        "                f.write(\"Assistant: \" + str(assistant) + \"\\n\")\n",
        "                f.write(\"-\" * 60 + \"\\n\")\n",
        "        return path\n",
        "    except Exception as e:\n",
        "        logging.exception(\"Failed to write transcript\")\n",
        "        raise\n",
        "\n",
        "# -------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "def summarize_file(file):\n",
        "    \"\"\"Read and summarize an uploaded file (PDF or TXT).\"\"\"\n",
        "    if file is None:\n",
        "        return \"⚠️ Please upload a file.\"\n",
        "\n",
        "    try:\n",
        "        text_content = \"\"\n",
        "\n",
        "        # Handle .txt files\n",
        "        if file.name.lower().endswith(\".txt\"):\n",
        "            with open(file.name, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "                text_content = f.read()\n",
        "\n",
        "        # Handle .pdf files\n",
        "        elif file.name.lower().endswith(\".pdf\"):\n",
        "            from PyPDF2 import PdfReader\n",
        "            reader = PdfReader(file.name)\n",
        "            for page in reader.pages[:5]:  # Limit to first 5 pages\n",
        "                text_content += page.extract_text() or \"\"\n",
        "\n",
        "        else:\n",
        "            return \"⚠️ Unsupported file format. Please upload a PDF or TXT file.\"\n",
        "\n",
        "        if not text_content.strip():\n",
        "            return \"⚠️ Could not extract meaningful content from the file.\"\n",
        "\n",
        "        # Summarize with AI\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Summarize the following document in 3–4 concise sentences.\"},\n",
        "                {\"role\": \"user\", \"content\": text_content[:4000]}  # Truncate for efficiency\n",
        "            ],\n",
        "            max_tokens=250  #lower number prevents overly long completions. In this case 250 is low which is good if you want to keep concise\n",
        "        )\n",
        "        return completion.choices[0].message.content\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"⚠️ Error summarizing file: {str(e)}\"\n",
        "\n",
        "\n",
        "\n",
        "# def summarize_file(file):\n",
        "#     \"\"\"Placeholder function to summarize an uploaded file.\"\"\"\n",
        "#     if file is None:\n",
        "#         return \"Please upload a file.\"\n",
        "\n",
        "#     # You would add your file reading and summarization logic here.\n",
        "#     return f\"This is a placeholder summary of the file at: {file.name}\"\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def summarize_url(url):\n",
        "    \"\"\"Fetch and summarize the main text content of a URL.\"\"\"\n",
        "    if not url or not url.startswith((\"http://\", \"https://\")):\n",
        "        return \"⚠️ Please enter a valid URL (must start with http:// or https://).\"\n",
        "\n",
        "    try:\n",
        "        # Fetch webpage\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Parse HTML\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        paragraphs = [p.get_text(strip=True) for p in soup.find_all(\"p\")]\n",
        "        text_content = \" \".join(paragraphs[:10])  # Limit to first 10 paragraphs for efficiency\n",
        "\n",
        "        if not text_content.strip():\n",
        "            return \"⚠️ Could not extract meaningful content from the page.\"\n",
        "\n",
        "        # Summarize with AI\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Summarize the webpage content in 3–4 concise sentences.\"},\n",
        "                {\"role\": \"user\", \"content\": text_content}\n",
        "            ],\n",
        "            max_tokens=150\n",
        "        )\n",
        "        return completion.choices[0].message.content\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"⚠️ Failed to fetch URL: {str(e)}\"\n",
        "    except Exception as e:\n",
        "        return f\"⚠️ Error summarizing URL: {str(e)}\"\n",
        "\n",
        "\n",
        "# def summarize_url(url):\n",
        "#     \"\"\"Placeholder function to summarize a URL's content.\"\"\"\n",
        "#     if not url or not url.startswith((\"http://\", \"https://\")):\n",
        "#         return \"Please enter a valid URL.\"\n",
        "\n",
        "    # You would add your web scraping and summarization logic here.\n",
        "    return f\"This is a placeholder summary of the content from the URL: {url}\"\n",
        "\n",
        "# -------------------------------------------------------------------------------------\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# ----------------- Gradio App Logic -----------------\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "\n",
        "def respond(user_input, audio_filepath, history, url_input=None, file_input=None):\n",
        "    global voice_enabled\n",
        "\n",
        "    # Handle summarization requests first\n",
        "    if url_input:\n",
        "        summary = summarize_url(url_input)\n",
        "        history.append((f\"Summarize URL: {url_input}\", summary))\n",
        "        return history, \"\", None, None\n",
        "\n",
        "    if file_input:\n",
        "        summary = summarize_file(file_input)\n",
        "        history.append((f\"Summarize File: {file_input.name}\", summary))\n",
        "        return history, \"\", None, None\n",
        "\n",
        "    # Handle chat messages\n",
        "    if not user_input and not audio_filepath:\n",
        "        return history, \"\", None, None\n",
        "\n",
        "    message = user_input\n",
        "    if audio_filepath:\n",
        "        # NOTE: You need to implement your own transcription logic here.\n",
        "        message = \"Transcribing audio... (This feature needs a real transcription tool)\"\n",
        "\n",
        "    # Handle voice toggle commands\n",
        "    if message.lower() == \"voice on\":\n",
        "        voice_enabled = True\n",
        "        response = \"🔊 Voice enabled.\"\n",
        "    elif message.lower() == \"voice off\":\n",
        "        voice_enabled = False\n",
        "        response = \"🔇 Voice disabled.\"\n",
        "    else:\n",
        "        try:\n",
        "            response = chat_with_agent(message, history)\n",
        "        except Exception as e:\n",
        "            tb = traceback.format_exc()\n",
        "            logging.exception(\"Error while calling agent\")\n",
        "            response = f\"⚠️ Agent Error: {str(e)}\\n\\n```\\n{tb}\\n```\"\n",
        "\n",
        "    audio_output = None\n",
        "    if voice_enabled and not response.startswith(\"⚠️\"):\n",
        "        try:\n",
        "            audio_output_file = text_to_speech(response)\n",
        "            if audio_output_file and os.path.exists(audio_output_file):\n",
        "                audio_output = audio_output_file\n",
        "        except Exception as e:\n",
        "            logging.exception(\"TTS generation failed\")\n",
        "            audio_output = None\n",
        "\n",
        "    if audio_output:\n",
        "        history.append((message, (response, audio_output)))\n",
        "    else:\n",
        "        history.append((message, response))\n",
        "\n",
        "    return history, \"\", None, None\n",
        "\n",
        "# -------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def respond_with_tts(user_text, mic_file, history, url_input, file_upload):\n",
        "    if history is None:\n",
        "        history = []\n",
        "\n",
        "    # 1️⃣ Append user message immediately\n",
        "    history.append((user_text, \"\"))\n",
        "\n",
        "    # 2️⃣ Generate bot response\n",
        "    bot_response = respond(user_text, mic_file, history, url_input, file_upload)[0][-1][1]\n",
        "\n",
        "    # 3️⃣ Update last entry with bot response\n",
        "    history[1] = (user_text, bot_response)\n",
        "\n",
        "    # 4️⃣ Convert bot response to speech\n",
        "    audio_file = tts_tool.run(bot_response)\n",
        "\n",
        "    return history, None, None, None, audio_file\n",
        "\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# ----------------- Gradio UI -----------------\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "with gr.Blocks(css=\"\"\"\n",
        "    .gr-chat-message.user {background-color: #E0F7FA; border-radius: 10px; padding: 5px;}\n",
        "    .gr-chat-message.bot {background-color: #FFF3E0; border-radius: 10px; padding: 5px;}\n",
        "    .gr-button {background-color: #29B6F6; color: white;}\n",
        "\"\"\") as demo:\n",
        "\n",
        "    gr.Markdown(\"## 🤖 AI Content Coach\")\n",
        "    gr.Markdown(\"Type your question or speak it. Use the sidebar for additional features.\")\n",
        "\n",
        "    chatbot = gr.Chatbot(label=\"Chat History\", elem_id=\"chatbot\", type=\"tuples\", height=400)\n",
        "    history = gr.State([])   # ✅ persistent chat history\n",
        "\n",
        "    # Audio output for TTS\n",
        "    audio_output = gr.Audio(label=\"Speech Output\", type=\"filepath\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=3):\n",
        "            msg = gr.Textbox(label=\"Your Question\", placeholder=\"Type here...\", lines=1)\n",
        "            mic = gr.Microphone(label=\"🎤 Speak\", type=\"filepath\", sources=\"microphone\")\n",
        "            clear_button = gr.Button(\"Clear Chat\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### Features\")\n",
        "            url_input = gr.Textbox(label=\"Summarize URL\", placeholder=\"Paste a URL here\")\n",
        "            file_upload = gr.File(label=\"Summarize File\", file_types=[\"pdf\", \"txt\"])\n",
        "            download_button = gr.Button(\"Download Chat Transcript\")\n",
        "            file_output = gr.File(label=\"Download File\")\n",
        "\n",
        "    # ----------------- Event listeners -----------------\n",
        "    msg.submit(\n",
        "        fn=respond_with_tts,\n",
        "        inputs=[msg, gr.State(None), history, url_input, file_upload],\n",
        "        outputs=[chatbot, msg, url_input, file_upload, audio_output]\n",
        "    )\n",
        "\n",
        "    mic.change(\n",
        "        fn=respond_with_tts,\n",
        "        inputs=[gr.State(None), mic, history, url_input, file_upload],\n",
        "        outputs=[chatbot, msg, url_input, file_upload, audio_output]\n",
        "    )\n",
        "\n",
        "    url_input.submit(\n",
        "        fn=respond_with_tts,\n",
        "        inputs=[gr.State(None), gr.State(None), history, url_input, file_upload],\n",
        "        outputs=[chatbot, msg, url_input, file_upload, audio_output]\n",
        "    )\n",
        "\n",
        "    file_upload.change(\n",
        "        fn=respond_with_tts,\n",
        "        inputs=[gr.State(None), gr.State(None), history, url_input, file_upload],\n",
        "        outputs=[chatbot, msg, url_input, file_upload, audio_output]\n",
        "    )\n",
        "\n",
        "    clear_button.click(lambda: ([], None, None, None, None), inputs=None, outputs=[chatbot, msg, url_input, file_upload, audio_output])\n",
        "\n",
        "    download_button.click(\n",
        "        fn=download_transcript,\n",
        "        inputs=[history],\n",
        "        outputs=[file_output]\n",
        "    )\n",
        "\n",
        "# Launch the app\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "6Emaw8JqP1Zj",
        "outputId": "587d96d1-054d-4da2-bca0-6e273c4e8ae5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-43636367.py:306: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(label=\"Chat History\", elem_id=\"chatbot\", type=\"tuples\", height=400)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://1d2bf2e04446517f7f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1d2bf2e04446517f7f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}